{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prep, Selection, Tuning and Conclusion\n",
    "\n",
    "In this notebook, with the preprocessed data, I will apply a few models and select the best parameters to train the data. \n",
    "\n",
    "Contents:\n",
    "- [Imports](#Import-libraries-and-data)\n",
    "- [Model Prep](#Model-preparation)\n",
    "- [Model Selection](#Model-selection)\n",
    "- [Model Hyperparameter Tuning and Evaluation](#Model-hyperparameter-tuning-and-evaluation)\n",
    "- [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from prettytable import PrettyTable\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter s ban on trump strips us of moral high...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>parler finds refuge with right leaning webhost...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sorry cleveland</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>elon musk a lot of people are going to be supe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>democrat law professor trump never actually ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titles  subreddit\n",
       "0  twitter s ban on trump strips us of moral high...          1\n",
       "1  parler finds refuge with right leaning webhost...          1\n",
       "2                                    sorry cleveland          1\n",
       "3  elon musk a lot of people are going to be supe...          1\n",
       "4  democrat law professor trump never actually ca...          1"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "titles_lemm = pd.read_csv(\"../data/titles_lemm.csv\")\n",
    "titles_stemm = pd.read_csv(\"../data/titles_stemm.csv\")\n",
    "comments_lemm = pd.read_csv(\"../data/comments_lemm.csv\")\n",
    "comments_stemm = pd.read_csv(\"../data/comments_stemm.csv\")\n",
    "#check\n",
    "titles_lemm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model preparation\n",
    "\n",
    "Split data into X (text feature) and y (target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtl = titles_lemm['titles'].astype('U').values# pandas series cos countvectorizer requires a vector\n",
    "ytl = titles_lemm['subreddit'].astype('U').values\n",
    "\n",
    "Xts = titles_stemm['titles'].astype('U').values # pandas series cos countvectorizer requires a vector\n",
    "yts = titles_stemm['subreddit'].astype('U').values\n",
    "\n",
    "Xcl = comments_lemm['comments'].astype('U').values # pandas series cos countvectorizer requires a vector\n",
    "ycl = comments_lemm['subreddit'].astype('U').values\n",
    "\n",
    "Xcs = comments_stemm['comments'].astype('U').values # pandas series cos countvectorizer requires a vector\n",
    "ycs = comments_stemm['subreddit'].astype('U').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there is an imbalanced class, I apply random oversampling, using RandomOverSampler (ROS) to balance the class. With random oversampling, randomly selected samples from the minority class will be appended, with replacement, to the original dataset (Imbalanced-learn, 2017)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate\n",
    "ros = RandomOverSampler(sampling_strategy = 'minority')\n",
    "#fit\n",
    "Xtl_ros, ytl_ros = ros.fit_resample(Xtl.reshape(-1,1),ytl) \n",
    "Xts_ros, yts_ros = ros.fit_resample(Xts.reshape(-1,1),yts)\n",
    "Xcl_ros, ycl_ros = ros.fit_resample(Xcl.reshape(-1,1),ycl)\n",
    "Xcs_ros, ycs_ros = ros.fit_resample(Xcs.reshape(-1,1),ycs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to array suitable to fit\n",
    "Xtl_ros = Xtl_ros.ravel()\n",
    "Xts_ros = Xts_ros.ravel()\n",
    "Xcl_ros = Xcl_ros.ravel()\n",
    "Xcs_ros = Xcs_ros.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training and test sets, then split the training set into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and testing set\n",
    "Xtl_train, Xtl_test, ytl_train, ytl_test = train_test_split(Xtl_ros, ytl_ros, random_state = 42)\n",
    "Xts_train, Xts_test, yts_train, yts_test = train_test_split(Xts_ros, yts_ros, random_state = 42)\n",
    "Xcl_train, Xcl_test, ycl_train, ycl_test = train_test_split(Xcl_ros, ycl_ros, random_state = 42)\n",
    "Xcs_train, Xcs_test, ycs_train, ycs_test = train_test_split(Xcs_ros, ycs_ros, random_state = 42)\n",
    "\n",
    "# split train set into train and validation set\n",
    "Xtl_train, Xtl_val, ytl_train, ytl_val = train_test_split(Xtl_train, ytl_train, random_state = 42)\n",
    "Xts_train, Xts_val, yts_train, yts_val = train_test_split(Xts_train, yts_train, random_state = 42)\n",
    "Xcl_train, Xcl_val, ycl_train, ycl_val = train_test_split(Xcl_train, ycl_train, random_state = 42)\n",
    "Xcs_train, Xcs_val, ycs_train, ycs_val = train_test_split(Xcs_train, ycs_train, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first fit data into a few pipeline models, without changing the parameters. This will be the baseline model from which I will then score and select the best performing model to go forward with. In evaluating the models, there a few metrics considered below (Vidhya, 2020) : \n",
    "\n",
    "| Metric | Elaboration and Analysis |\n",
    "| :-----: | :-------- | \n",
    "| Accuracy | provides fraction of predictions that the model got right (ie. number of correct predictions / total number of predictions). This metric may not work well on imbalanced classes like the data I collected, but since I have balanced the classes with `RandomOverSampling`, I can rely on the accuracy metric.  |\n",
    "| Precision | provides the fraction of correctly identified positives out of all predicted positives. [TP / (TP + FP)]. This indicates how much we can trust the algorithm when it predicts a class. |\n",
    "| Recall/Sensitivity | provides the fraction of correctly identified as positive out of all positives. [TP / (TP + FN)] . This shows how many of the true labels of the class is predicted correctly. |\n",
    "| F1-score | a harmonic mean of precision and recall. While we want to maximise precision and recall, it is a trade-off. Since I have no bias towards any classes (ie. predicting a post to be from `r/Conservative` is as good/bad as predicting a post to be from `r/democrats`), the F1 score may not as important as accuracy, foy this project. |\n",
    "\n",
    "Once selected the best performing model, I will then tune the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipelines\n",
    "pipe1 = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipe2 = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe3 = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "pipe4 = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipe5 = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('sv', SVC())\n",
    "])\n",
    "\n",
    "#params\n",
    "pipe1_params = {}\n",
    "pipe2_params = {}\n",
    "pipe3_params = {}\n",
    "pipe4_params = {}\n",
    "pipe5_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pipe into gridsearch but without param changes, using f1 as the scoring method\n",
    "gs1 = GridSearchCV(pipe1, param_grid = pipe1_params, cv = 5)\n",
    "gs2 = GridSearchCV(pipe2, param_grid = pipe2_params, cv = 5)\n",
    "gs3 = GridSearchCV(pipe3, param_grid = pipe3_params, cv = 5)\n",
    "gs4 = GridSearchCV(pipe4, param_grid = pipe4_params, cv = 5)\n",
    "gs5 = GridSearchCV(pipe5, param_grid = pipe5_params, cv = 5)\n",
    "\n",
    "# fit model on first pipe\n",
    "gs1.fit(Xtl_train,ytl_train)\n",
    "gs1_tl_score = round(gs1.best_score_,3)\n",
    "gs1_tl_train_score = round(gs1.score(Xtl_train,ytl_train),3)\n",
    "gs1_tl_val_score = round(gs1.score(Xtl_val,ytl_val),3)\n",
    "\n",
    "gs1.fit(Xts_train,yts_train)\n",
    "gs1_ts_score = round(gs1.best_score_,3)\n",
    "gs1_ts_train_score = round(gs1.score(Xts_train,yts_train),3)\n",
    "gs1_ts_val_score = round(gs1.score(Xts_val,yts_val),3)\n",
    "\n",
    "gs1.fit(Xcl_train,ycl_train)\n",
    "gs1_cl_score = round(gs1.best_score_,3)\n",
    "gs1_cl_train_score = round(gs1.score(Xcl_train,ycl_train),3)\n",
    "gs1_cl_val_score = round(gs1.score(Xcl_val,ycl_val),3)\n",
    "\n",
    "gs1.fit(Xcs_train,ycs_train)\n",
    "gs1_cs_score = round(gs1.best_score_,3)\n",
    "gs1_cs_train_score = round(gs1.score(Xcs_train,ycs_train),3)\n",
    "gs1_cs_val_score = round(gs1.score(Xcs_val,ycs_val),3)\n",
    "\n",
    "# fit model on second pipe\n",
    "gs2.fit(Xtl_train,ytl_train)\n",
    "gs2_tl_score = round(gs2.best_score_,3)\n",
    "gs2_tl_train_score = round(gs2.score(Xtl_train,ytl_train),3)\n",
    "gs2_tl_val_score = round(gs2.score(Xtl_val,ytl_val),3)\n",
    "\n",
    "gs2.fit(Xts_train,yts_train)\n",
    "gs2_ts_score = round(gs2.best_score_,3)\n",
    "gs2_ts_train_score = round(gs2.score(Xts_train,yts_train),3)\n",
    "gs2_ts_val_score = round(gs2.score(Xts_val,yts_val),3)\n",
    "\n",
    "gs2.fit(Xcl_train,ycl_train)\n",
    "gs2_cl_score = round(gs2.best_score_,3)\n",
    "gs2_cl_train_score = round(gs2.score(Xcl_train,ycl_train),3)\n",
    "gs2_cl_val_score = round(gs2.score(Xcl_val,ycl_val),3)\n",
    "\n",
    "gs2.fit(Xcs_train,ycs_train)\n",
    "gs2_cs_score = round(gs2.best_score_,3)\n",
    "gs2_cs_train_score = round(gs2.score(Xcs_train,ycs_train),3)\n",
    "gs2_cs_val_score = round(gs2.score(Xcs_val,ycs_val),3)\n",
    "\n",
    "# fit model on third pipe\n",
    "gs3.fit(Xtl_train,ytl_train)\n",
    "gs3_tl_score = round(gs3.best_score_,3)\n",
    "gs3_tl_train_score = round(gs3.score(Xtl_train,ytl_train),3)\n",
    "gs3_tl_val_score = round(gs3.score(Xtl_val,ytl_val),3)\n",
    "\n",
    "gs3.fit(Xts_train,yts_train)\n",
    "gs3_ts_score = round(gs3.best_score_,3)\n",
    "gs3_ts_train_score = round(gs3.score(Xts_train,yts_train),3)\n",
    "gs3_ts_val_score = round(gs3.score(Xts_val,yts_val),3)\n",
    "\n",
    "gs3.fit(Xcl_train,ycl_train)\n",
    "gs3_cl_score = round(gs3.best_score_,3)\n",
    "gs3_cl_train_score = round(gs3.score(Xcl_train,ycl_train),3)\n",
    "gs3_cl_val_score = round(gs3.score(Xcl_val,ycl_val),3)\n",
    "\n",
    "gs3.fit(Xcs_train,ycs_train)\n",
    "gs3_cs_score = round(gs3.best_score_,3)\n",
    "gs3_cs_train_score = round(gs3.score(Xcs_train,ycs_train),3)\n",
    "gs3_cs_val_score = round(gs3.score(Xcs_val,ycs_val),3)\n",
    "\n",
    "# fit model on fourth pipe\n",
    "gs4.fit(Xtl_train,ytl_train)\n",
    "gs4_tl_score = round(gs4.best_score_,3)\n",
    "gs4_tl_train_score = round(gs4.score(Xtl_train,ytl_train),3)\n",
    "gs4_tl_val_score = round(gs4.score(Xtl_val,ytl_val),3)\n",
    "\n",
    "gs4.fit(Xts_train,yts_train)\n",
    "gs4_ts_score = round(gs4.best_score_,3)\n",
    "gs4_ts_train_score = round(gs4.score(Xts_train,yts_train),3)\n",
    "gs4_ts_val_score = round(gs4.score(Xts_val,yts_val),3)\n",
    "\n",
    "gs4.fit(Xcl_train,ycl_train)\n",
    "gs4_cl_score = round(gs4.best_score_,3)\n",
    "gs4_cl_train_score = round(gs4.score(Xcl_train,ycl_train),3)\n",
    "gs4_cl_val_score = round(gs4.score(Xcl_val,ycl_val),3)\n",
    "\n",
    "gs4.fit(Xcs_train,ycs_train)\n",
    "gs4_cs_score = round(gs4.best_score_,3)\n",
    "gs4_cs_train_score = round(gs4.score(Xcs_train,ycs_train),3)\n",
    "gs4_cs_val_score = round(gs4.score(Xcs_val,ycs_val),3)\n",
    "\n",
    "# fit model on fourth pipe\n",
    "gs5.fit(Xtl_train,ytl_train)\n",
    "gs5_tl_score = round(gs5.best_score_,3)\n",
    "gs5_tl_train_score = round(gs5.score(Xtl_train,ytl_train),3)\n",
    "gs5_tl_val_score = round(gs5.score(Xtl_val,ytl_val),3)\n",
    "\n",
    "gs5.fit(Xts_train,yts_train)\n",
    "gs5_ts_score = round(gs5.best_score_,3)\n",
    "gs5_ts_train_score = round(gs5.score(Xts_train,yts_train),3)\n",
    "gs5_ts_val_score = round(gs5.score(Xts_val,yts_val),3)\n",
    "\n",
    "gs5.fit(Xcl_train,ycl_train)\n",
    "gs5_cl_score = round(gs5.best_score_,3)\n",
    "gs5_cl_train_score = round(gs5.score(Xcl_train,ycl_train),3)\n",
    "gs5_cl_val_score = round(gs5.score(Xcl_val,ycl_val),3)\n",
    "\n",
    "gs5.fit(Xcs_train,ycs_train)\n",
    "gs5_cs_score = round(gs5.best_score_,3)\n",
    "gs5_cs_train_score = round(gs5.score(Xcs_train,ycs_train),3)\n",
    "gs5_cs_val_score = round(gs5.score(Xcs_val,ycs_val),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------+\n",
      "|                 Results of Pipeline 1 (Count Vectorizer, Logistic Regression)                  |\n",
      "+----------------------------------+-------------+--------------+---------------+----------------+\n",
      "|                                  | Titles_Lemm | Titles_Stemm | Comments_Lemm | Comments_Stemm |\n",
      "+----------------------------------+-------------+--------------+---------------+----------------+\n",
      "| Best accuracy score across folds |    0.814    |    0.814     |     0.914     |     0.913      |\n",
      "|   Accuracy score on Train Set    |    0.994    |    0.996     |     0.983     |     0.985      |\n",
      "| Accuracy score on Validation Set |    0.786    |    0.821     |     0.931     |     0.932      |\n",
      "+----------------------------------+-------------+--------------+---------------+----------------+\n",
      "+------------------------------------------------------------------------------------------------+\n",
      "|               Results of Pipeline 2 (Tf-idf Vectorizer, Multinomial Naive Bayes)               |\n",
      "+----------------------------------+-------------+--------------+---------------+----------------+\n",
      "|                                  | Titles_Lemm | Titles_Stemm | Comments_Lemm | Comments_Stemm |\n",
      "+----------------------------------+-------------+--------------+---------------+----------------+\n",
      "| Best accuracy score across folds |    0.804    |    0.813     |     0.894     |     0.886      |\n",
      "|   Accuracy score on Train Set    |    0.963    |    0.962     |     0.954     |     0.955      |\n",
      "| Accuracy score on Validation Set |    0.791    |    0.818     |     0.901     |     0.897      |\n",
      "+----------------------------------+-------------+--------------+---------------+----------------+\n",
      "+------------------------------------------------------------------------------------------------+\n",
      "|               Results of Pipeline 3 (Count Vectorizer, Decision Tree Classifier)               |\n",
      "+----------------------------------+-------------+--------------+---------------+----------------+\n",
      "|                                  | Titles_Lemm | Titles_Stemm | Comments_Lemm | Comments_Stemm |\n",
      "+----------------------------------+-------------+--------------+---------------+----------------+\n",
      "| Best accuracy score across folds |    0.779    |    0.758     |     0.878     |     0.882      |\n",
      "|   Accuracy score on Train Set    |     1.0     |     1.0      |     0.993     |     0.994      |\n",
      "| Accuracy score on Validation Set |    0.783    |    0.802     |     0.905     |     0.891      |\n",
      "+----------------------------------+-------------+--------------+---------------+----------------+\n",
      "+------------------------------------------------------------------------------------------------+\n",
      "|               Results of Pipeline 4 (Count Vectorizer, Random Forest Classifier)               |\n",
      "+----------------------------------+-------------+--------------+---------------+----------------+\n",
      "|                                  | Titles_Lemm | Titles_Stemm | Comments_Lemm | Comments_Stemm |\n",
      "+----------------------------------+-------------+--------------+---------------+----------------+\n",
      "| Best accuracy score across folds |    0.825    |    0.827     |     0.948     |     0.951      |\n",
      "|   Accuracy score on Train Set    |     1.0     |     1.0      |     0.993     |     0.994      |\n",
      "| Accuracy score on Validation Set |    0.781    |    0.818     |     0.969     |     0.968      |\n",
      "+----------------------------------+-------------+--------------+---------------+----------------+\n",
      "+------------------------------------------------------------------------------------------------+\n",
      "|              Results of Pipeline 5 (Count Vectorizer, Support Vector Classifier)               |\n",
      "+----------------------------------+-------------+--------------+---------------+----------------+\n",
      "|                                  | Titles_Lemm | Titles_Stemm | Comments_Lemm | Comments_Stemm |\n",
      "+----------------------------------+-------------+--------------+---------------+----------------+\n",
      "| Best accuracy score across folds |    0.793    |    0.803     |     0.853     |     0.865      |\n",
      "|   Accuracy score on Train Set    |    0.982    |    0.986     |     0.927     |     0.934      |\n",
      "| Accuracy score on Validation Set |    0.767    |    0.807     |      0.88     |     0.883      |\n",
      "+----------------------------------+-------------+--------------+---------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "# view results in table \n",
    "x = PrettyTable(title = \"Results of Pipeline 1 (Count Vectorizer, Logistic Regression)\", header_style = 'title', max_table_width = 120)\n",
    "x.field_names = [\" \", \"titles_lemm\", \"titles_stemm\", \"comments_lemm\", \"comments_stemm\"]\n",
    "x.add_row([\"Best accuracy score across folds\", gs1_tl_score, gs1_ts_score , gs1_cl_score, gs1_cs_score])\n",
    "x.add_row([\"Accuracy score on Train Set\", gs1_tl_train_score, gs1_ts_train_score, gs1_cl_train_score, gs1_cs_train_score])\n",
    "x.add_row([\"Accuracy score on Validation Set\", gs1_tl_val_score, gs1_ts_val_score, gs1_cl_val_score, gs1_cs_val_score])\n",
    "print(x)\n",
    "\n",
    "y = PrettyTable(title = \"Results of Pipeline 2 (Tf-idf Vectorizer, Multinomial Naive Bayes)\", header_style = 'title', max_table_width = 120)\n",
    "y.field_names = [\" \", \"titles_lemm\", \"titles_stemm\", \"comments_lemm\", \"comments_stemm\"]\n",
    "y.add_row([\"Best accuracy score across folds\", gs2_tl_score, gs2_ts_score , gs2_cl_score, gs2_cs_score])\n",
    "y.add_row([\"Accuracy score on Train Set\", gs2_tl_train_score, gs2_ts_train_score, gs2_cl_train_score, gs2_cs_train_score])\n",
    "y.add_row([\"Accuracy score on Validation Set\", gs2_tl_val_score, gs2_ts_val_score, gs2_cl_val_score, gs2_cs_val_score])\n",
    "print(y)\n",
    "\n",
    "z = PrettyTable(title = \"Results of Pipeline 3 (Count Vectorizer, Decision Tree Classifier)\", header_style = 'title', max_table_width = 120)\n",
    "z.field_names = [\" \", \"titles_lemm\", \"titles_stemm\", \"comments_lemm\", \"comments_stemm\"]\n",
    "z.add_row([\"Best accuracy score across folds\", gs3_tl_score, gs3_ts_score , gs3_cl_score, gs3_cs_score])\n",
    "z.add_row([\"Accuracy score on Train Set\", gs3_tl_train_score, gs3_ts_train_score, gs3_cl_train_score, gs3_cs_train_score])\n",
    "z.add_row([\"Accuracy score on Validation Set\", gs3_tl_val_score, gs3_ts_val_score, gs3_cl_val_score, gs3_cs_val_score])\n",
    "print(z)\n",
    "\n",
    "a = PrettyTable(title = \"Results of Pipeline 4 (Count Vectorizer, Random Forest Classifier)\", header_style = 'title', max_table_width = 120)\n",
    "a.field_names = [\" \", \"titles_lemm\", \"titles_stemm\", \"comments_lemm\", \"comments_stemm\"]\n",
    "a.add_row([\"Best accuracy score across folds\", gs4_tl_score, gs4_ts_score , gs4_cl_score, gs4_cs_score])\n",
    "a.add_row([\"Accuracy score on Train Set\", gs4_tl_train_score, gs4_ts_train_score, gs4_cl_train_score, gs4_cs_train_score])\n",
    "a.add_row([\"Accuracy score on Validation Set\", gs4_tl_val_score, gs4_ts_val_score, gs4_cl_val_score, gs4_cs_val_score])\n",
    "print(a)\n",
    "\n",
    "b = PrettyTable(title = \"Results of Pipeline 5 (Count Vectorizer, Support Vector Classifier)\", header_style = 'title', max_table_width = 120)\n",
    "b.field_names = [\" \", \"titles_lemm\", \"titles_stemm\", \"comments_lemm\", \"comments_stemm\"]\n",
    "b.add_row([\"Best accuracy score across folds\", gs5_tl_score, gs5_ts_score , gs5_cl_score, gs5_cs_score])\n",
    "b.add_row([\"Accuracy score on Train Set\", gs5_tl_train_score, gs5_ts_train_score, gs5_cl_train_score, gs5_cs_train_score])\n",
    "b.add_row([\"Accuracy score on Validation Set\", gs5_tl_val_score, gs5_ts_val_score, gs5_cl_val_score, gs5_cs_val_score])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results, I note the following :\n",
    "\n",
    "1. Comments always have a better score than titles, so I willl use the comments data to train in the final model. This is expected since there is more data available in comments than titles (ie. there can be several hundreds of comments on a particular post)  \n",
    "\n",
    "\n",
    "2. Generally, stemmed words have a better score than lemmatized words. This is likely because words used in both `r/Conservative` and `r/democrats` are already very distinct from each other, such that a harsher truncation by stemming makes the model more effective. \n",
    "\n",
    "\n",
    "3. Comparing scores on train set, the `RandomForestClassifier` and the `DecisionTreeClassifier` were the best performing model. However, when looking at the average `cross_val_score`, the `RandomForestClassifier` did better. \n",
    "\n",
    "\n",
    "Based on this analysis, I will move forward with the `RandomForestClassifier` model (ie. Pipeline 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model hyperparameter tuning and evaluation\n",
    "I now tune the hyperparameters of the pipeline so it can perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best accuracy score is : 0.9740546342745734\n",
      "The best parameters are : {'cvec__min_df': 2, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': None, 'rf__max_depth': None}\n",
      "+---------------------------------------------------+\n",
      "| Best Score and Parameters on Training and Test Set  |\n",
      "+-------------------------+-------------------------+\n",
      "|         Dataset         |      Accuracy Score     |\n",
      "+-------------------------+-------------------------+\n",
      "|      Training Set       |          0.994          |\n",
      "|      Validation Set     |          0.985          |\n",
      "|         Test Set        |          0.979          |\n",
      "+-------------------------+-------------------------+\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# insert parameters to search over\n",
    "pipe4_params = {\n",
    "    'cvec__ngram_range': [(1,1), (1,2)],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'cvec__min_df': [2, 3, 6], # limits vocab size by requiring a term appearing in x number of documents to be considered as part of the vocabulary\n",
    "    'rf__max_depth': [None, 1, 3]\n",
    "}\n",
    "# load pipe into grid search\n",
    "gs = GridSearchCV(pipe4, param_grid = pipe4_params, cv = 5)\n",
    "\n",
    "# fit model\n",
    "gs.fit(Xcs_train, ycs_train)\n",
    "\n",
    "# view best score\n",
    "print(f'The best accuracy score is : {gs.best_score_}')\n",
    "print(f'The best parameters are : {gs.best_params_}')\n",
    "\n",
    "#view results in a table\n",
    "c = PrettyTable(title = \"Best Score and Parameters on Training and Test Set \", header_style = 'title', max_table_width = 110)\n",
    "c.field_names = [\"Dataset\", \"Accuracy Score\"]\n",
    "c.add_row([\"Training Set \", round(gs.score(Xcs_train,ycs_train),3)])\n",
    "c.add_row([\"Validation Set\", round(gs.score(Xcs_val,ycs_val),3)])\n",
    "c.add_row([\"Test Set\", round(gs.score(Xcs_test,ycs_test),3)])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From tuning of the hyperparameters, the model performed better than the baseline. Looking at the best parameters,I note the following:\n",
    "\n",
    "1. Surprisingly, not removing stop words improved the model. This suggests that stop words help in making sense of the data with respect to each subreddit. \n",
    "\n",
    "\n",
    "2. ngram range is (1,2) which means both unigrams and bigrams (ie. single words or two words back-to-back) are considered together in training the model to help it perform better. \n",
    "\n",
    "Comparing results to the test set, there is only a small overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best accuracy score is : 0.9736360051698834\n",
      "+--------------------------------------------------------------------------+\n",
      "| Accuracy Score with Best Parameters on Training, Validation and Test Set  |\n",
      "+--------------------------------------------------+-----------------------+\n",
      "|                     Dataset                      |     Accuracy Score    |\n",
      "+--------------------------------------------------+-----------------------+\n",
      "|         Accuracy score on Training Set           |         0.994         |\n",
      "|         Accuracy score on Validation Set         |         0.985         |\n",
      "|            Accuracy score on Test Set            |         0.979         |\n",
      "+--------------------------------------------------+-----------------------+\n",
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# insert best parameters\n",
    "pipex_params = {\n",
    "    'cvec__ngram_range': [(1,2)],\n",
    "    'cvec__stop_words': [None],\n",
    "    'cvec__min_df': [2], # limits vocab size by requiring a term appearing in x number of documents to be considered as part of the vocabulary\n",
    "    'rf__max_depth': [None]\n",
    "}\n",
    "# load pipe into grid search\n",
    "gsx = GridSearchCV(pipe4, param_grid = pipex_params, cv = 5)\n",
    "\n",
    "# fit model\n",
    "gsx.fit(Xcs_train, ycs_train)\n",
    "\n",
    "# view best score\n",
    "print(f'The best accuracy score is : {gsx.best_score_}')\n",
    "\n",
    "#view results in a table\n",
    "d = PrettyTable(title = \"Accuracy Score with Best Parameters on Training, Validation and Test Set \", header_style = 'title', max_table_width = 110)\n",
    "d.field_names = [\"Dataset\", \"Accuracy Score\"]\n",
    "d.add_row([\"Accuracy score on Training Set \", round(gsx.score(Xcs_train,ycs_train),3)])\n",
    "d.add_row([\"Accuracy score on Validation Set\", round(gsx.score(Xcs_val,ycs_val),3)])\n",
    "d.add_row([\"Accuracy score on Test Set\", round(gsx.score(Xcs_test,ycs_test),3)])\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gsx.predict(Xcs_test)\n",
    "y_pred = [int(numeric_list) for numeric_list in y_pred]\n",
    "ycs_test = [int(numeric_list) for numeric_list in ycs_test]\n",
    "# y_probs = gs.predict_proba(Xcs_test)\n",
    "accuracy_score = round(accuracy_score(ycs_test, y_pred),3)\n",
    "precision_score = round(precision_score(ycs_test, y_pred),3)\n",
    "recall_score = round(recall_score(ycs_test, y_pred),3)\n",
    "f1_score = round(f1_score(ycs_test, y_pred),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------+\n",
      "|                           Overview of Scores                          |\n",
      "+----------+----------------+-----------------+--------------+----------+\n",
      "| Dataset  | Accuracy Score | Precision Score | Recall Score | F1 Score |\n",
      "+----------+----------------+-----------------+--------------+----------+\n",
      "| Test Set |     0.979      |      0.969      |     0.99     |  0.979   |\n",
      "+----------+----------------+-----------------+--------------+----------+\n"
     ]
    }
   ],
   "source": [
    "# view results in table\n",
    "e = PrettyTable(title = \"Overview of Scores\", header_style = 'title', max_table_width = 120)\n",
    "e.field_names = [\"Dataset\", \"Accuracy Score\", \"Precision Score\", \"Recall Score\", \"F1 Score\"]\n",
    "e.add_row([\"Test Set\", accuracy_score, precision_score, recall_score, f1_score])\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = gs.predict_proba(Xcs_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(ycs_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.4f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the ROC AUC curve, with a well-performing model, we see that the AUC is close to one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Random Forest Classifier performed really well to classify a post between `r/Conservative` and `r/democrats`. This is expected as from the data exploration done earlier, we see pretty distinct words used in each of these subreddits. While we would expect similar topics to be discussed or similar mentions in both `r/Conservative` and  `r/democrats`, from our results, it appears that the content that is discussed in each subreddit goes in very different directions (ie. redditors use very distinct words for each subreddit).\n",
    "\n",
    "**Further Development**\n",
    "\n",
    "With this model, we can perform further sentiment analysis and from public sentiment, we could predict outcomes of future elections. Businesses would then be able to prepare for policy changes and if needed pivot the business in favour of any upcoming policy changes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "\"Over-sampling\" (Imbalanced-learn, 2017)\n",
    "https://imbalanced-learn.org/stable/over_sampling.html#random-over-sampler\n",
    "\n",
    "\"CountVectorizer in Python\" (Educative Inc.,2021)\n",
    "https://www.educative.io/edpresso/countvectorizer-in-python\n",
    "\n",
    "\"Feature extraction from text using CountVectorizer & TfidfVectorizer\" (Wang, 2020)\n",
    "https://medium.com/@wenxuan0923/feature-extraction-from-text-using-countvectorizer-tfidfvectorizer-9f74f38f86cc\n",
    "\n",
    "\"How to Choose Evaluation Metrics for Classification Models\" (Vidhya, 2020)\n",
    "https://www.analyticsvidhya.com/blog/2020/10/how-to-choose-evaluation-metrics-for-classification-model/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
